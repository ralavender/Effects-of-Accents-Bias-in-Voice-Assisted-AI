# Effects-of-Accents-Bias-in-Voice-Assisted-AI
This project presents the evaluation of Whisper by OpenAI, a speech-to-text transcription and speech recognition model to investigate the impact of various Chinese accents on the overall fairness of automatic speech recognition (ASR) systems. We utilized a dataset from Mozilla’s Common Voice project and NexData to evaluate performance disparities between native English speakers and Chinese-accented English speakers by comparing each group’s accuracy scores. In our context, accuracy scores are calculated from the Word Error Rate (WER) and Character Error Rate (CER). Additionally, we explored the influence of gender on these performance metrics, with the potential to identify algorithmic bias related to these features.

Our findings predict significant accuracy differences between the two linguistic groups, highlighting potential biases in the ASR model. We explore the intersectionality of demographic factors, race, and gender, to understand how these biases may compound. The study integrates ethical principles, including fairness and inclusivity, while adhering to legal standards like GDPR and anti-discrimination laws. Results will inform strategies to mitigate algorithmic bias, improve model performance across linguistic diversity, and promote equitable user experiences.

By addressing disparities in ASR systems, this work contributes to broader AI fairness and AI-human interaction goals by emphasizing the need for inclusive data sampling, transparency, and ethical design. Our findings aim to foster advancements in voice recognition technology, ensuring accessibility and equity for all users.

Rhett Lavender, Data Science B.S., Junior
Arjun Mahesh, Computer Science B.S., Sophomore
Rebekah Northrup, Statistics and Analytics B.S., Data Science B.A., Sophomore
Shana Tran, Computer Science B.A., Data Science B.A., Junior
